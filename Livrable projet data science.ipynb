{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Livrable Projet DATA SCIENCE</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contexte\n",
    "\n",
    "L'entreprise TouNum est une entreprise de numérisation de documents. Elle prospose différents services dont la numérisation de base de document papier pour les entreprises clientes. TouNum veut optimiser et rendre intelligent ce processus de scanning en incluant des outils de Machine Learning. Le gain de temps serait important aux vues des nombreuses données que l'entreprise doit scanner et étiqueter.\n",
    "Pour cela, TouNum fait appel à CESI pour réaliser cette prestation.\n",
    "\n",
    "### Objectif\n",
    "\n",
    "L'objectif est que l'équipe de data scientist de CESI réalise cette solution visant à analyser des photographies pour en déterminer une légende descriptive de manière automatique. Il faudra également améliorer la qualité des images scannées ayant des qualités variables (parfois floues, ou bruitées).\n",
    "\n",
    "<img src=\"imageSrc/caption image.PNG\"/>\n",
    "\n",
    "### Enjeux\n",
    "\n",
    "TouNum devait trier et étiqueter chaque document scanné. La solution délivré par CESI permet l'automatisation de ces tâches en faisant donc gagner un temps non négligeable. Elle va donc pouvoir réaliser plus de contrats et augmenter la satisfaction client.\n",
    "\n",
    "### Contraintes techniques\n",
    "\n",
    "L'implémentation des algorithmes doit être réaliser sur Python, notamment les librairies Scikit et TensorFlow. La librairie Pandas doit être utilisé pour manipuler le dataset et ImageIO pour le charger. NumPy et MatPlotLib seront nécessaire pour le calcul scientifique et la modélisation.\n",
    "\n",
    "Le programme à livrer devra respecter le workflow suivant :\n",
    "\n",
    "<img src=\"imageSrc/workflow.PNG\"/>\n",
    "\n",
    "#### Classification:\n",
    "\n",
    "La classification d'image se fera à l'aide de réseaux de neurones. Cette dernière doit distinguer les photos d'un autre documents, tel que schémas, textes scannés, voir peintures.\n",
    "TouNoum possède un dataset rempli d'images divers pour entrainer le réseau de neurones.\n",
    "\n",
    "#### Prétraitement\n",
    "\n",
    "Le prétraitement dois utiliser des filtres convolutifs afin d'améliorer la qualité. Il doit établir un compromis entre débruitage et affutage.\n",
    "\n",
    "#### Captionning\n",
    "\n",
    "Le Captionning devra légender automatiquement les images. Il utilisera deux techniques de Machine Learning : les réseaux de neurones convolutifs (CNN) pour prétraiter l'image en identifiant les zones d’intérêt, et les réseaux de neurones récurrents (RNN) pour générer les étiquettes. Il faudra être vigilant quant aux ressources RAM. Un dataset d'étiquetage classique est disponible pour l’apprentissage supervisé.\n",
    "\n",
    "### Livrable\n",
    "\n",
    "La solution doit sous forme de notebook Jupiter entièrement automatisé. Il doit être conçu pour être faciliter mis en production et maintenance.\n",
    "Il faut démontrer la pertinence du modèle de manière rigoureuse et pédagogique.\n",
    "\n",
    "#### Jalons\n",
    "\n",
    "CESI devra dois rendre le prototype complet et fonctionnel du programme pour le 23 janvier. \n",
    "TouNum exige également 3 dates de rendu pour suivre la bonne avancé du projet.\n",
    "<ul>\n",
    "    <li>18/12/20 : Prétraitement d'image</li>\n",
    "    <li>15/01/21 : Classification binaire</li>\n",
    "    <li>20/01/21 : Captioning d'images</li>\n",
    "    <li>22/01/21 : Démonstration </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Livrable 1 - Prétraitement (denoising/sharpening…)\n",
    "\n",
    "Le but est de traiter un ensemble de photographies afin de les rendre mieux traitables par les algorithmes de Machine Learning. Il y a deux traitements à réaliser : le débruitage, et l’affutage. Vous devrez produire un notebook Jupyter explicitant ces étapes de prétraitement, et leurs performances. Ces algorithmes s’appuieront sur des notions assez simples autour des filtres de convolution, et les appliqueront pour améliorer la qualité de l’image. Il faudra notamment décider d’un compromis entre dé-bruitage et affutage.\n",
    "\n",
    "Le notebook devra intégrer :\n",
    "<ul>\n",
    "    <li>Le code de chargement du fichier.</li>\n",
    "    <li>Le code du débruitage sur un sous-ensemble d’images bruitées. Le code doit être accompagné d’explications.</li>\n",
    "    <li>Le code de l’affutage sur un sous-ensembles d’images floutées. Le code doit être accompagné d’explications.</li>\n",
    "    <li>\n",
    "        Une étude de cas explicitant les compromis entre ces deux opérations. Cette partie du livrable doit inclure le bruitage d’images et montrer la perte de détails, ou l’affutage d’images et montrer l’apparition du bruit.\n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "<b>Ce livrable est à fournir pour le 18/12/2020</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importation des librairies utilisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install opencv-python\n",
    "!pip3 install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import cv2\n",
    "import threading\n",
    "from queue import Queue\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.restoration import estimate_sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Méthodes utilisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des images\n",
    "def get_image(path, filename):\n",
    "    return io.imread(path + filename)\n",
    "\n",
    "# Sauvegarde des images\n",
    "def save_image(path, filename, content):\n",
    "    #Check if folder exists\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "    imageio.imwrite(path + filename , content)\n",
    "\n",
    "# Retrieve importants informations from data    \n",
    "def get_metric_stat(pre_data, post_data):\n",
    "    data = [\n",
    "        np.array([min(pre_data), max(pre_data), np.median(pre_data), np.average(pre_data)]),\n",
    "        np.array([min(post_data), max(post_data), np.median(post_data), np.average(post_data)])\n",
    "    ]\n",
    "\n",
    "    data_array = pd.DataFrame(data,\n",
    "                              index = [\"pre_processed\", \"post_processed\"],\n",
    "                              columns = [\"Min value\", \"Max value\", \"Median value\", \"Average value\"])\n",
    "    print(data_array)\n",
    "\n",
    "# Display all data in table\n",
    "def get_list_data(data_tmp):\n",
    "    data_array = pd.DataFrame(np.array(data_tmp),\n",
    "                              columns = [\"Name\", \"Before\", \"After\"])\n",
    "    print(\"\\n\")\n",
    "    print(data_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Défloutage de l'image\n",
    "\n",
    "Pour le défloutage les images, on passe par le filtrage via **convolution**. L'opération de convolution consiste à faire glisser une autre matrice nommée filtre (de taille généralement inférieure à l'image traitée) tout le long de l'image et remplacer la valeur de chaque pixel de l'image par la somme du produit des éléments de cette matrice.\n",
    "\n",
    "Les filtres d'amélioration de la netteté d'une image (ou filtres d'affutage de contours) permettent d'améliorer la qualité d'une image en accentuant les bords (ou en d'autres termes en accentuant les différences entres les pixels adjacents). L'affutage de contour consiste à prendre des différences.\n",
    "\n",
    "Pour le défloutage des images, on utilise un **filtre Laplacien**.\n",
    "Ce filtre nous permet d'affuter les images grâce à une fonction de convolution de la librairie opencv sur l'image récupérée.\n",
    "La variante de filtre choisie nous permet sur le jeu de données fourni d'affuter les images suffisamment pour retirer le flou présent sans pour autant y ajouter de bruit.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explication de la matrice Laplacienne\n",
    "\n",
    "\n",
    "L'approximation utilisée pour calculer le Laplacien est (si on prend la somme des l'approximation de la dérivée au sens des abscisses et des ordonnées) exprimée sous la forme $F(x+1,y)+F(x-1,y)+F(x,y+1)+F(x,y-1)-4F(x,y)$).\n",
    "\n",
    "Ce qui nous donne la matrice suivante et sa variante prenant en compte les diagonales (en effet, il existe une multitude de variantes):\n",
    "\n",
    "<img src=\"imageSrc/conv-laplacian.jpg\"/>\n",
    "\n",
    "La matrice de Laplace permet de mettre en évidence les contours d'une image comme on peut le voir selon l'image suivante:\n",
    "\n",
    "<img src=\"imageSrc/laplacian_filtered_image.jpg\"/>\n",
    "\n",
    "On voit donc mieux les contours, mais on perds le sens de l'image de départ. Pour corriger cela, on ajoute donc la matrice identitaire (l'image de départ) sur l'image d'arrivé, d'où le coefficient 9 au lieux de 8 (cf image ci dessous):\n",
    "\n",
    "<img src=\"imageSrc/laplace_conv_original.jpg\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deblurring function\n",
    "def remove_blur(img, high):\n",
    "    kernel = []\n",
    "    \n",
    "    if high:\n",
    "        # Creation of a Laplacian kernel to use for debluring\n",
    "        kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "    else:\n",
    "        kernel = np.array([[0,-1,0], [-1,5,-1], [0,-1,0]])\n",
    "    \n",
    "    # Convolution of the kernel with the image given in the function's parameter\n",
    "    return cv2.filter2D(img, -1, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métrique d'évaluation du niveau de flou\n",
    "\n",
    "Pour évaluer le niveau de flou, on utilise les contours Laplacien sur l'image (cf image ci dessus) et on évalue la variance de Laplace. Une variance faible indique qu'une faible plage de gris est utilisé (en d'autres termes, qu'il n'y a pas beaucoup de nuance utilisé, et donc qui se caractérise par du flou). Une variance élevé correspond donc à une large plage de gris utilisé (donc beaucoup plus de nuance disponible pour les détails). \n",
    "\n",
    "Il faut être vigilant à certaines images, tel qu'une photo du ciel, ou la variance sera faible même si cette dernière est net. L'indicateur devra alors être interprété en fonction du contexte.\n",
    "\n",
    "<img src=\"imageSrc/Laplace_Variance.jpg\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blurry_indicator(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    fm = cv2.Laplacian(gray_image, cv2.CV_64F).var()\n",
    "    return fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of files to treat\n",
    "folder = \"./Dataset/Blurry/\"\n",
    "listing = os.listdir(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution\n",
    "\n",
    "<ul>\n",
    "    <li> Utilisation de threads pour optimiser le temps d'éxecution </li>\n",
    "    <li> Calcul de la variance avant et après traitement </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Thread execution\n",
    "def process_fpath(name):\n",
    "    path = folder+name\n",
    "    img = get_image(folder,name)\n",
    "\n",
    "     # Get initial Blur metric\n",
    "    original_blur_metric = get_blurry_indicator(img)\n",
    "    pre_processed_data.append(original_blur_metric)\n",
    "    \n",
    "    # Remove blur from the colored image image\n",
    "    deblurred_img = remove_blur(img, high=True)\n",
    "\n",
    "    # Get initial Blur metric\n",
    "    processed_blur_metric = get_blurry_indicator(deblurred_img)\n",
    "    post_processed_data.append(processed_blur_metric)\n",
    "    \n",
    "    #print(\"image \" + name + \" - initial : \" + str(original_blur_metric)\n",
    "     #   + \" - processed : \" + str(processed_blur_metric)\n",
    "     #   + \" - difference : \" + str(processed_blur_metric - original_blur_metric)+\"\\n\")\n",
    "\n",
    "    data_preview_blurr.append([name, original_blur_metric, processed_blur_metric])\n",
    "\n",
    "    # Saving Image\n",
    "    save_image(\"./Dataset/processed/deblurred/\", name, deblurred_img)\n",
    "\n",
    "# Loop on the list of file\n",
    "threads = []\n",
    "pre_processed_data = []\n",
    "post_processed_data = []\n",
    "data_preview_blurr = []\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for name in listing:\n",
    "        #process_fpath(name)\n",
    "        t = threading.Thread(target=process_fpath, args=(name,))\n",
    "        threads.append(t)\n",
    "        \n",
    "    # Start them all\n",
    "    for thread in threads:\n",
    "        thread.start()\n",
    "\n",
    "    # Wait for all to complete\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    \n",
    "    get_metric_stat(pre_processed_data, post_processed_data)\n",
    "    get_list_data(data_preview_blurr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "plt.figure(figsize=(24, 8))\n",
    "\n",
    "def display_image_diff(originalPath, diffPath, filename=None):\n",
    "    if not filename:\n",
    "        # Get a random file from directory\n",
    "        filename = random.choice(os.listdir(originalPath)) \n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.imshow(get_image(originalPath, filename))\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Original Image\")\n",
    "    \n",
    "    # Corrected Image noise\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(get_image(diffPath, filename))\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Corrected Image\")\n",
    "    \n",
    "# Filename MUST be the same for both directories    \n",
    "display_image_diff(\"./Dataset/Blurry/\", \"./Dataset/processed/deblurred/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Débruitage\n",
    "La capture d'un signal lumineux par un appareil photographique s'accompagne le plus souvent d'informations non désirées : le « bruit ». \n",
    "L'essentiel de ce « bruit » (des pixels trop clairs ou trop sombre en trop grand nombre ou de manière irrégulière, par exemple) est dû au capteur.\n",
    "\n",
    "### Le débruitage par morceaux (par patchs)\n",
    "Le débruitage par morceaux est une technique de débruitage d'image utilisant l'algorithme de réduction du bruit numérique appelé en Anglais \"non-local means\".\n",
    "La méthode repose sur un principe simple, remplacer la couleur d'un pixel par une moyenne des couleurs de pixels similaires. Mais les pixels les plus similaires à un pixel donné n'ont aucune raison d'être proches. Il est donc nécessaire de scanner une vaste partie de l'image à la recherche de tous les pixels qui ressemblent vraiment au pixel que l'on veut débruiter.\n",
    "\n",
    "### Pourquoi cette methode ?\n",
    "Le résultat d'un tel filtrage permet d’amoindrir la perte de détails au sein de l'image, comparé aux filtres réalisant des moyennes localement tel que le filtre de Gauss ou le filtre de Wiener, le bruit généré par l'algorithme \"non-local means\" est plus proche du bruit blanc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Syntax:**\n",
    "cv2.fastNlMeansDenoisingColored( P1, P2, float P3, float P4, int P5, int P6)\n",
    "\n",
    "**Parameters:**\n",
    "* P1 – Source Image Array\n",
    "* P2 – Destination Image Array\n",
    "* P3 – Size in pixels of the template patch that is used to compute weights.\n",
    "* P4 – Size in pixels of the window that is used to compute a weighted average for the given pixel.\n",
    "* P5 – Parameter regulating filter strength for luminance component.\n",
    "* P6 – Same as above but for color components // Not used in a grayscale image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Noise function\n",
    "def remove_noise(image, high):\n",
    "    if high == 2:\n",
    "        return cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 15)\n",
    "    elif high == 1:\n",
    "        return cv2.fastNlMeansDenoisingColored(image, None, 5, 10, 7, 15)\n",
    "    else:\n",
    "        return cv2.fastNlMeansDenoisingColored(image, None, 3, 3, 7, 15)\n",
    "\n",
    "def estimate_noise(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return estimate_sigma(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of files to treat\n",
    "folder = \"./Dataset/Noisy/\"\n",
    "listing = os.listdir(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thread execution\n",
    "def process_fpath(name):\n",
    "    path = folder+name\n",
    "    img = get_image(folder,name)\n",
    "    \n",
    "    # Get initial noise metric\n",
    "    original_noise_metric = estimate_noise(img)\n",
    "    pre_processed_data.append(original_noise_metric)\n",
    "    \n",
    "    denoised_img = remove_noise(img, high=2)\n",
    "    \n",
    "    # Get initial noise metric\n",
    "    processed_noise_metric = estimate_noise(denoised_img)\n",
    "    post_processed_data.append(processed_noise_metric)\n",
    "\n",
    "    data_preview_denoised.append([name, original_noise_metric, processed_noise_metric])\n",
    "    \n",
    "    save_image(\"./Dataset/processed/denoised/\", name, denoised_img)\n",
    "\n",
    "# Loop on the list of file\n",
    "threads = []\n",
    "pre_processed_data = []\n",
    "post_processed_data = []\n",
    "data_preview_denoised = []\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for name in listing:\n",
    "        #process_fpath(name)\n",
    "        t = threading.Thread(target=process_fpath, args=(name,))\n",
    "        threads.append(t)\n",
    "        \n",
    "    # Start them all\n",
    "    for thread in threads:\n",
    "        thread.start()\n",
    "\n",
    "    # Wait for all to complete\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    \n",
    "    get_metric_stat(pre_processed_data, post_processed_data)\n",
    "    get_list_data(data_preview_denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24, 8))\n",
    "\n",
    "# Filename MUST be the same for both directories    \n",
    "display_image_diff(\"./Dataset/Noisy/\", \"./Dataset/processed/denoised/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimisation entre Défloutage et Débruitage\n",
    "Afin d'améliorer l'image au maximum, on peut effectuer les 2 operations à savoir, le traitement de bruit et le traitement de flou, sur une même image et utiliser nos métriques de performances pour automatiser l'application des traitements. Un autre point d'importance, l'ordre dans lequel on effectue les traitements a un impact sur la qualité de l'image.\n",
    "\n",
    "### Procédé d'amelioration\n",
    "Afin de determiner la qualité générale d'une image en termes de bruit et de flou, on utilise la moyenne des mesures effectuées précedement sur les differents jeux de tests. En fonction de la première mesure de l'image, on décide de commencer par un débruitage ou un défloutage. Ensuite, une nouvelle mesure est effectuée et est comparée à nouveau avec les mesures des jeux de données post traitement. \n",
    "Si l'image n'est toujours pas considérées viable, on effectue l'opération inverse à plus faible intensité pour essayer d'avoir le meilleur compromis. Pour ces traitements, on se limite à deux passages pour éviter de détériorer l'image à analyser et pour éviter des temps de traitements trop longs. \n",
    "\n",
    "### Résultats\n",
    "Le résultat de ces tests a permis de demontrer que la meilleure solution consiste a commencer par effectuer un defloutage à forte intensité sur l'image puis, si c'est nécessaire, un debruitage à basse intensité. Cela représente le meilleur compromis au niveau de la qualité génerale de l'image.\n",
    "\n",
    "L'affichage de ces test est disponible ci-dessous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose noisy or blurry image\n",
    "noisy = False\n",
    "\n",
    "img = []\n",
    "#if you want random testing\n",
    "#img = get_image(\"./Dataset/Blurry/\", random.choice(os.listdir(\"./Dataset/Blurry/\")))\n",
    "\n",
    "#image retrival\n",
    "if noisy:\n",
    "    img = get_image(\"./Dataset/Noisy/\", \"noisy_117.jpg\")\n",
    "\n",
    "else:\n",
    "    img = get_image(\"./Dataset/Blurry/\", \"blurry_092.jpg\")\n",
    "\n",
    "#initial image measurements\n",
    "initial_noise = estimate_noise(img)\n",
    "initial_blur = get_blurry_indicator(img)\n",
    "\n",
    "# print(initial_noise, initial_blur)\n",
    "\n",
    "#image is blurry\n",
    "if initial_blur < 3000:\n",
    "    # high deblur of the image\n",
    "    img_stage2 = remove_blur(img, high=False)\n",
    "    \n",
    "    #second image measurements\n",
    "    second_noise = estimate_noise(img)\n",
    "    second_blur = get_blurry_indicator(img)\n",
    "    \n",
    "    #image meets requirements in terms of noise\n",
    "    if second_noise < 1:\n",
    "        #displaying images\n",
    "        plt.figure(figsize=(24, 8))\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Original Image\")\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(img_stage2)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Corrected Image with only 1 deblur\")\n",
    "        plt.show()\n",
    "    \n",
    "    #image doesn't meets requirements in terms of noise\n",
    "    else:\n",
    "        #low denoise of the image\n",
    "        img_stage3 = remove_noise(img_stage2, 0)\n",
    "        \n",
    "        img_stage3_low_noise = remove_noise(img_stage2, 0)\n",
    "        \n",
    "        #displaying images\n",
    "        plt.figure(figsize=(24, 8))\n",
    "        plt.subplot(131)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Original Image\")\n",
    "        plt.subplot(132)\n",
    "        plt.imshow(img_stage2)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Corrected Image with only 1 deblur\")\n",
    "        plt.subplot(133)\n",
    "        plt.imshow(img_stage3)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Corrected Image with 1 deblur and 1 low denoise\")\n",
    "        plt.show()\n",
    "        plt.figure(figsize=(24, 8))\n",
    "        plt.subplot(141)\n",
    "        plt.imshow(img_stage3_low_noise)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Corrected Image with 1 deblur and 1 low denoise\")\n",
    "        plt.show()\n",
    "        \n",
    "#if image is noisy      \n",
    "if initial_noise > 1:\n",
    "    # high denoise of the image\n",
    "    img_stage2 = remove_noise(img, 2)\n",
    "    \n",
    "    img_stage2_low_noise = remove_noise(img, 1)\n",
    "    \n",
    "    #second image measurements\n",
    "    second_noise = estimate_noise(img)\n",
    "    second_blur = get_blurry_indicator(img)\n",
    "    \n",
    "    #image meets requirements in terms of blur\n",
    "    if second_blur > 48000:\n",
    "        #displaying images\n",
    "        plt.figure(figsize=(24, 8))\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Original Image\")\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(img_stage2)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Corrected Image with only 1 deblur\")\n",
    "        plt.subplot(123)\n",
    "        plt.imshow(img_stage2_low_noise)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Corrected Image with only 1 deblur\")\n",
    "        plt.show()\n",
    "    \n",
    "    #image meets requirements in terms of blur\n",
    "    else:\n",
    "        #low deblur of the image\n",
    "        img_stage3 = remove_blur(img_stage2, high=False)\n",
    "        img_stage3_low_noise = remove_blur(img_stage2, high=False)\n",
    "        \n",
    "        #displaying images\n",
    "        plt.figure(figsize=(24, 8))\n",
    "        plt.subplot(131)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Original Image\")\n",
    "        plt.subplot(132)\n",
    "        plt.imshow(img_stage2)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Corrected Image with only 1 denoise\")\n",
    "        plt.subplot(133)\n",
    "        plt.imshow(img_stage2_low_noise)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Corrected Image with only 1 medium denoise\")\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(24, 8))\n",
    "        plt.subplot(131)\n",
    "        plt.imshow(img_stage3)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Corrected Image with 1 denoise and 1 low deblur\")\n",
    "        plt.figure(figsize=(24, 8))\n",
    "        plt.subplot(132)\n",
    "        plt.imshow(img_stage3_low_noise)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Corrected Image with 1 medium denoise and 1 low deblur\")\n",
    "        plt.show()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "## Image\n",
    "\n",
    "\n",
    "## Défloutage\n",
    "\n",
    "* https://www.pyimagesearch.com/2015/09/07/blur-detection-with-opencv/\n",
    "* https://stackoverflow.com/questions/48319918/whats-the-theory-behind-computing-variance-of-an-image\n",
    "\n",
    "## Debruitage\n",
    "* https://docs.opencv.org/3.4/d5/d69/tutorial_py_non_local_means.html\n",
    "* http://www.ipol.im/pub/art/2011/bcm_nlm/article.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow-gpu\n",
    "#!pip install tensorflow_datasets\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import pathlib\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "\n",
    "print(tf.__version__)\n",
    "print(len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model():\n",
    "    data_dir = pathlib.Path('./RN/Dataset')\n",
    "    batch_size = 32\n",
    "\n",
    "    train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "      data_dir,\n",
    "      validation_split=0.2,\n",
    "      subset=\"training\",\n",
    "      seed=123,\n",
    "      image_size=(180, 180),\n",
    "      batch_size=batch_size)\n",
    "\n",
    "    \n",
    "    print(\"Classes found :\")\n",
    "    print(train_ds.class_names)\n",
    "    normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
    "\n",
    "    num_classes = len(train_ds.class_names)\n",
    "\n",
    "    val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "      data_dir,\n",
    "      validation_split=0.2,\n",
    "      subset=\"validation\",\n",
    "      seed=123,\n",
    "      image_size=(180, 180),\n",
    "      batch_size=batch_size)\n",
    "\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "    train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "      layers.experimental.preprocessing.Rescaling(1./255),\n",
    "      layers.Conv2D(32, 3, activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Conv2D(32, 3, activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Conv2D(32, 3, activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(128, activation='relu'),\n",
    "      layers.Dense(num_classes)\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "      optimizer='adam',\n",
    "      loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "      metrics=['accuracy'])\n",
    "\n",
    "    model.fit(\n",
    "      train_ds,\n",
    "      validation_data=val_ds,\n",
    "      epochs=2\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def classify_image(model, impath):\n",
    "\n",
    "    img = image.load_img((impath) , target_size=(180,180))\n",
    "    img  = image.img_to_array(img)\n",
    "    img  = img.reshape((1,) + img.shape)\n",
    "    \n",
    "    #img_class=model.predict_classes(img)\n",
    "\n",
    "    prediction = model.predict(img)\n",
    "    score = tf.nn.softmax(prediction[0])\n",
    "    print(\n",
    "        \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "        .format(class_names[np.argmax(score)], 100 * np.max(score)))\n",
    "    \n",
    "    return [class_names[np.argmax(score)], 100 * np.max(score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = generate_model()\n",
    "\n",
    "result = classify_image(model, 'chart.png')\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "#####################################################################################\n",
    "#####################################################################################\n",
    "#####################################################################################\n",
    "#####################################################################################\n",
    "#####################################################################################\n",
    "\n",
    "#RESTES DE PROTOTYPES\n",
    "\n",
    "\n",
    "data_dir = pathlib.Path('./RN/Dataset')\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(180, 180),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(180, 180),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.Rescaling(1./255),\n",
    "  layers.Conv2D(32, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=2\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "impath = \"chart.png\"\n",
    "\n",
    "img = image.load_img((impath) , target_size=(180,180))\n",
    "img  = image.img_to_array(img)\n",
    "img  = img.reshape((1,) + img.shape)\n",
    "\n",
    "img_class=model.predict_classes(img)\n",
    "\n",
    "print(img_class)\n",
    "\n",
    "prediction = model.predict(img)\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "print(prediction[0][0])\n",
    "print(prediction[0][1])\n",
    "\n",
    "score = tf.nn.softmax(prediction[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n",
    "\n",
    "\n",
    "img_path = io.imread(impath)\n",
    "plt.imshow(img_path)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
